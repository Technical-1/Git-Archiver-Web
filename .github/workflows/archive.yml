name: Archive Repository

on:
  issues:
    types: [opened]  # Only trigger on open, not labeled (avoids double runs)
  workflow_dispatch:
    inputs:
      url:
        description: 'GitHub repository URL to archive'
        required: true
        type: string

# Permissions needed for creating releases and commenting on issues
permissions:
  contents: write
  issues: write

# Ensure only one archive job runs at a time
concurrency:
  group: archive-${{ github.event.issue.number || github.run_id }}
  cancel-in-progress: false

jobs:
  archive:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    # Only run if issue has archive-request label OR manual dispatch
    if: |
      (github.event_name == 'issues' && contains(github.event.issue.labels.*.name, 'archive-request')) ||
      github.event_name == 'workflow_dispatch'

    # Prevent race conditions in index updates
    concurrency:
      group: index-update-global
      cancel-in-progress: false

    steps:
      - name: Setup retry function
        run: |
          cat > /tmp/retry.sh << 'RETRY_SCRIPT'
          #!/bin/bash
          MAX_ATTEMPTS=$1
          shift
          ATTEMPT=1
          DELAY=5
          while [ $ATTEMPT -le $MAX_ATTEMPTS ]; do
            if "$@"; then exit 0; fi
            [ $ATTEMPT -lt $MAX_ATTEMPTS ] && sleep $DELAY && DELAY=$((DELAY * 2))
            ATTEMPT=$((ATTEMPT + 1))
          done
          exit 1
          RETRY_SCRIPT
          chmod +x /tmp/retry.sh

      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Parse repository URL
        id: parse
        env:
          ISSUE_BODY: ${{ github.event.issue.body }}
          INPUT_URL: ${{ github.event.inputs.url }}
          EVENT_NAME: ${{ github.event_name }}
        run: |
          if [ "$EVENT_NAME" == "workflow_dispatch" ]; then
            URL="$INPUT_URL"
          else
            # Extract URL from issue body (safely using env var)
            URL=$(echo "$ISSUE_BODY" | grep -oP 'url:\s*\K(https://github\.com/[^\s]+)' | head -1)
          fi

          # Validate URL format strictly - only allow safe characters
          if ! [[ "$URL" =~ ^https://github\.com/[a-zA-Z0-9_.-]+/[a-zA-Z0-9_.-]+/?$ ]]; then
            echo "Invalid URL format: $URL"
            echo "valid=false" >> $GITHUB_OUTPUT
            exit 0
          fi

          echo "url=$URL" >> $GITHUB_OUTPUT

          # Parse owner and repo
          if [[ "$URL" =~ github\.com/([^/]+)/([^/]+) ]]; then
            OWNER="${BASH_REMATCH[1]}"
            REPO="${BASH_REMATCH[2]}"
            REPO="${REPO%.git}"
            REPO="${REPO%/}"

            # Sanitize owner and repo to prevent path traversal
            OWNER="${OWNER//\//_}"
            OWNER="${OWNER//../_}"
            REPO="${REPO//\//_}"
            REPO="${REPO//../_}"

            echo "owner=$OWNER" >> $GITHUB_OUTPUT
            echo "repo=$REPO" >> $GITHUB_OUTPUT
            echo "valid=true" >> $GITHUB_OUTPUT

            # Generate release tag
            DATE=$(date +%Y-%m-%d)
            TAG="${OWNER}__${REPO}__${DATE}"
            echo "tag=$TAG" >> $GITHUB_OUTPUT
            echo "date=$DATE" >> $GITHUB_OUTPUT
          else
            echo "valid=false" >> $GITHUB_OUTPUT
          fi

          echo "Parsed URL: $URL"
          echo "Owner: $OWNER, Repo: $REPO"

      - name: Validate repository
        id: validate
        if: steps.parse.outputs.valid == 'true'
        run: |
          OWNER="${{ steps.parse.outputs.owner }}"
          REPO="${{ steps.parse.outputs.repo }}"

          echo "Checking repository: $OWNER/$REPO"

          # Fetch repository info from GitHub API
          RESPONSE=$(curl -s -w "\n%{http_code}" \
            -H "Accept: application/vnd.github.v3+json" \
            -H "User-Agent: Git-Archiver" \
            "https://api.github.com/repos/$OWNER/$REPO")

          HTTP_CODE=$(echo "$RESPONSE" | tail -1)
          BODY=$(echo "$RESPONSE" | sed '$d')

          if [ "$HTTP_CODE" != "200" ]; then
            echo "Repository not found or inaccessible (HTTP $HTTP_CODE)"
            echo "valid=false" >> $GITHUB_OUTPUT
            echo "error=Repository not found" >> $GITHUB_OUTPUT
            exit 0
          fi

          # Check if private
          IS_PRIVATE=$(echo "$BODY" | jq -r '.private')
          if [ "$IS_PRIVATE" == "true" ]; then
            echo "Cannot archive private repositories"
            echo "valid=false" >> $GITHUB_OUTPUT
            echo "error=Private repository" >> $GITHUB_OUTPUT
            exit 0
          fi

          # Get repository info
          SIZE_KB=$(echo "$BODY" | jq -r '.size')
          SIZE_MB=$((SIZE_KB / 1024))
          DESCRIPTION=$(echo "$BODY" | jq -r '.description // empty')
          IS_ARCHIVED=$(echo "$BODY" | jq -r '.archived')
          STARS=$(echo "$BODY" | jq -r '.stargazers_count')

          echo "Size: ${SIZE_MB}MB, Stars: $STARS, Archived: $IS_ARCHIVED"

          # Check size limit (2GB = 2097152 KB)
          if [ "$SIZE_KB" -gt 2097152 ]; then
            echo "Repository too large: ${SIZE_MB}MB"
            echo "valid=false" >> $GITHUB_OUTPUT
            echo "error=Repository too large (${SIZE_MB}MB > 2GB)" >> $GITHUB_OUTPUT
            exit 0
          fi

          echo "valid=true" >> $GITHUB_OUTPUT
          echo "size_mb=$SIZE_MB" >> $GITHUB_OUTPUT
          echo "description=$DESCRIPTION" >> $GITHUB_OUTPUT
          echo "is_archived=$IS_ARCHIVED" >> $GITHUB_OUTPUT
          echo "stars=$STARS" >> $GITHUB_OUTPUT

      - name: Clone repository
        if: steps.validate.outputs.valid == 'true'
        id: clone
        timeout-minutes: 10
        run: |
          URL="${{ steps.parse.outputs.url }}"
          SIZE_MB="${{ steps.validate.outputs.size_mb }}"

          # Adjust depth based on repo size
          if [ "$SIZE_MB" -lt 100 ]; then
            DEPTH="--depth 500"
          elif [ "$SIZE_MB" -lt 500 ]; then
            DEPTH="--depth 100"
          else
            DEPTH="--depth 50"
          fi

          echo "Cloning $URL with $DEPTH..."

          # Note: $DEPTH is intentionally unquoted to allow word splitting of "--depth N"
          timeout 540 git clone $DEPTH "$URL" repo || {
            echo "Clone failed or timed out"
            exit 1
          }

          # Verify clone
          [ -d "repo/.git" ] || exit 1

          cd repo
          echo "commit_hash=$(git rev-parse HEAD)" >> $GITHUB_OUTPUT
          echo "commit_date=$(git log -1 --format=%ci)" >> $GITHUB_OUTPUT
          echo "file_count=$(git ls-files | wc -l)" >> $GITHUB_OUTPUT

      - name: Create archive
        if: steps.validate.outputs.valid == 'true'
        id: archive
        timeout-minutes: 15
        run: |
          OWNER="${{ steps.parse.outputs.owner }}"
          REPO="${{ steps.parse.outputs.repo }}"
          ARCHIVE_NAME="${OWNER}_${REPO}.tar.gz"

          echo "Creating archive: $ARCHIVE_NAME"

          # Create tar.gz archive with repo name
          tar -czf "$ARCHIVE_NAME" -C repo .

          # Get archive size
          ARCHIVE_SIZE=$(stat -f%z "$ARCHIVE_NAME" 2>/dev/null || stat -c%s "$ARCHIVE_NAME")
          ARCHIVE_SIZE_MB=$((ARCHIVE_SIZE / 1024 / 1024))
          echo "Archive size: ${ARCHIVE_SIZE_MB}MB"

          # Check compressed archive size limit (1000MB)
          if [ "$ARCHIVE_SIZE_MB" -gt 1000 ]; then
            echo "ERROR: Compressed archive too large: ${ARCHIVE_SIZE_MB}MB (limit: 1000MB)"
            exit 1
          fi

          # Calculate archive hash for deduplication
          ARCHIVE_HASH=$(sha256sum "$ARCHIVE_NAME" | cut -d' ' -f1)
          echo "Archive hash: $ARCHIVE_HASH"

          echo "archive_name=$ARCHIVE_NAME" >> $GITHUB_OUTPUT
          echo "archive_size=$ARCHIVE_SIZE" >> $GITHUB_OUTPUT
          echo "archive_size_mb=$ARCHIVE_SIZE_MB" >> $GITHUB_OUTPUT
          echo "archive_hash=$ARCHIVE_HASH" >> $GITHUB_OUTPUT

      - name: Extract README
        if: steps.validate.outputs.valid == 'true'
        run: |
          # Find and copy README file
          cd repo
          README_FILE=$(find . -maxdepth 1 -iname 'readme*' -type f | head -1)
          if [ -n "$README_FILE" ]; then
            cp "$README_FILE" ../README.md
            echo "Found README: $README_FILE"
          else
            echo "# ${{ steps.parse.outputs.owner }}/${{ steps.parse.outputs.repo }}" > ../README.md
            echo "" >> ../README.md
            echo "${{ steps.validate.outputs.description }}" >> ../README.md
            echo "" >> ../README.md
            echo "*No README found in repository*" >> ../README.md
          fi
          cd ..

      - name: Create metadata
        if: steps.validate.outputs.valid == 'true'
        run: |
          # Use jq to safely create JSON with proper escaping
          jq -n \
            --arg url "${{ steps.parse.outputs.url }}" \
            --arg owner "${{ steps.parse.outputs.owner }}" \
            --arg repo "${{ steps.parse.outputs.repo }}" \
            --arg archived_at "$(date -u +%Y-%m-%dT%H:%M:%SZ)" \
            --arg commit_hash "${{ steps.clone.outputs.commit_hash }}" \
            --arg description "${{ steps.validate.outputs.description }}" \
            --argjson size_bytes "${{ steps.archive.outputs.archive_size || 0 }}" \
            --argjson original_size_mb "${{ steps.validate.outputs.size_mb || 0 }}" \
            --argjson stars "${{ steps.validate.outputs.stars || 0 }}" \
            --argjson is_archived "${{ steps.validate.outputs.is_archived || false }}" \
            --arg archive_hash "${{ steps.archive.outputs.archive_hash }}" \
            --arg archive_name "${{ steps.archive.outputs.archive_name }}" \
            '{
              url: $url,
              owner: $owner,
              repo: $repo,
              archived_at: $archived_at,
              commit_hash: $commit_hash,
              description: $description,
              size_bytes: $size_bytes,
              original_size_mb: $original_size_mb,
              stars: $stars,
              is_archived: $is_archived,
              archive_hash: $archive_hash,
              archive_name: $archive_name
            }' > metadata.json

          cat metadata.json

      - name: Check for changes from previous archive
        if: steps.validate.outputs.valid == 'true'
        id: check_changes
        run: |
          OWNER="${{ steps.parse.outputs.owner }}"
          REPO="${{ steps.parse.outputs.repo }}"
          NEW_HASH="${{ steps.archive.outputs.archive_hash }}"

          echo "New archive hash: $NEW_HASH"

          # Get all releases for this repo
          RELEASES=$(curl -s \
            -H "Accept: application/vnd.github.v3+json" \
            -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
            "https://api.github.com/repos/${{ github.repository }}/releases?per_page=100")

          # Find the most recent release for this owner/repo
          PREV_TAG=$(echo "$RELEASES" | jq -r --arg prefix "${OWNER}__${REPO}__" '
            [.[] | select(.tag_name | startswith($prefix))] | sort_by(.published_at) | last | .tag_name // empty
          ')

          if [ -z "$PREV_TAG" ]; then
            echo "No previous release found - will create new release"
            echo "has_changes=true" >> $GITHUB_OUTPUT
            exit 0
          fi

          echo "Previous release tag: $PREV_TAG"

          # Get previous metadata to compare hash
          PREV_METADATA_URL="https://github.com/${{ github.repository }}/releases/download/$PREV_TAG/metadata.json"
          PREV_HASH=$(curl -sL "$PREV_METADATA_URL" | jq -r '.archive_hash // empty')

          if [ -z "$PREV_HASH" ]; then
            echo "No previous hash found - will create new release"
            echo "has_changes=true" >> $GITHUB_OUTPUT
            exit 0
          fi

          echo "Previous archive hash: $PREV_HASH"

          if [ "$NEW_HASH" == "$PREV_HASH" ]; then
            echo "Archive hash unchanged - skipping release"
            echo "has_changes=false" >> $GITHUB_OUTPUT
          else
            echo "Archive hash changed - will create new release"
            echo "has_changes=true" >> $GITHUB_OUTPUT
          fi

      - name: Create GitHub Release
        if: steps.validate.outputs.valid == 'true' && steps.check_changes.outputs.has_changes == 'true'
        uses: softprops/action-gh-release@v1
        with:
          tag_name: ${{ steps.parse.outputs.tag }}
          name: "${{ steps.parse.outputs.owner }}/${{ steps.parse.outputs.repo }} - ${{ steps.parse.outputs.date }}"
          body: |
            Archive of [${{ steps.parse.outputs.owner }}/${{ steps.parse.outputs.repo }}](https://github.com/${{ steps.parse.outputs.owner }}/${{ steps.parse.outputs.repo }})

            - **Archived**: ${{ steps.parse.outputs.date }}
            - **Size**: ${{ steps.archive.outputs.archive_size_mb }}MB
            - **Stars**: ${{ steps.validate.outputs.stars }}
            - **Hash**: `${{ steps.archive.outputs.archive_hash }}`

            ${{ steps.validate.outputs.description }}
          files: |
            ${{ steps.archive.outputs.archive_name }}
            metadata.json
            README.md
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Backup existing index
        if: steps.validate.outputs.valid == 'true' && steps.check_changes.outputs.has_changes == 'true'
        id: backup_index
        run: |
          # Download existing index
          INDEX_URL="https://github.com/${{ github.repository }}/releases/download/index/index.json"

          echo "Attempting to download existing index from: $INDEX_URL"

          if curl -sL -o existing_index.json "$INDEX_URL" && [ -s existing_index.json ]; then
            # Check if it's valid JSON
            if jq -e '.' existing_index.json >/dev/null 2>&1; then
              echo "Valid index.json found, creating backup..."

              # Generate backup tag with timestamp
              BACKUP_TAG="index-backup-$(date -u +%Y%m%d-%H%M%S)"
              BACKUP_TIME=$(date -u +%Y-%m-%dT%H:%M:%SZ)

              echo "Backup tag: $BACKUP_TAG"
              echo "Backup time: $BACKUP_TIME"

              # Add backup metadata to the index
              jq --arg backup_tag "$BACKUP_TAG" \
                 --arg backup_time "$BACKUP_TIME" \
                 '. + {backup_metadata: {backup_tag: $backup_tag, backup_time: $backup_time, original_last_updated: .last_updated}}' \
                 existing_index.json > index_backup.json

              echo "Backup index created with metadata:"
              jq '.backup_metadata' index_backup.json

              echo "has_backup=true" >> $GITHUB_OUTPUT
              echo "backup_tag=$BACKUP_TAG" >> $GITHUB_OUTPUT
              echo "backup_time=$BACKUP_TIME" >> $GITHUB_OUTPUT
            else
              echo "Downloaded file is not valid JSON, skipping backup"
              echo "has_backup=false" >> $GITHUB_OUTPUT
            fi
          else
            echo "No existing index found or download failed, skipping backup"
            echo "has_backup=false" >> $GITHUB_OUTPUT
          fi

      - name: Upload index backup
        if: steps.backup_index.outputs.has_backup == 'true'
        uses: softprops/action-gh-release@v1
        with:
          tag_name: ${{ steps.backup_index.outputs.backup_tag }}
          name: "Index Backup - ${{ steps.backup_index.outputs.backup_time }}"
          body: |
            Automatic backup of index.json before update.

            **Backup Details:**
            - **Backup Tag:** `${{ steps.backup_index.outputs.backup_tag }}`
            - **Backup Time:** ${{ steps.backup_index.outputs.backup_time }}
            - **Triggered By:** Archive of ${{ steps.parse.outputs.owner }}/${{ steps.parse.outputs.repo }}
            - **Workflow Run:** [#${{ github.run_number }}](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})

            To restore this backup, use:
            ```bash
            ./scripts/restore-index.sh ${{ steps.backup_index.outputs.backup_tag }}
            ```
          files: index_backup.json
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Update index
        if: steps.validate.outputs.valid == 'true' && steps.check_changes.outputs.has_changes == 'true'
        run: |
          # Download existing index or create new one
          INDEX_URL="https://github.com/${{ github.repository }}/releases/download/index/index.json"

          # Download and validate that it's actually valid JSON
          if curl -sL -o index.json "$INDEX_URL" && [ -s index.json ] && jq -e '.' index.json >/dev/null 2>&1; then
            echo "Downloaded existing index with $(jq '.total_repos' index.json) repositories"
          else
            echo "No valid index found - creating new one"
            echo '{"repositories": {}, "total_repos": 0, "total_size_mb": 0, "last_updated": ""}' > index.json
          fi

          # Update index with jq
          REPO_URL="${{ steps.parse.outputs.url }}"
          OWNER="${{ steps.parse.outputs.owner }}"
          REPO="${{ steps.parse.outputs.repo }}"
          TAG="${{ steps.parse.outputs.tag }}"
          SIZE_MB="${{ steps.archive.outputs.archive_size_mb }}"
          DESCRIPTION="${{ steps.validate.outputs.description }}"
          STATUS="${{ steps.validate.outputs.is_archived == 'true' && 'archived' || 'active' }}"
          NOW=$(date -u +%Y-%m-%dT%H:%M:%SZ)

          # Check if repo already exists
          EXISTING=$(jq -r ".repositories[\"$REPO_URL\"]" index.json)

          if [ "$EXISTING" == "null" ]; then
            # Add new repository
            jq --arg url "$REPO_URL" \
               --arg owner "$OWNER" \
               --arg repo "$REPO" \
               --arg desc "$DESCRIPTION" \
               --arg status "$STATUS" \
               --arg tag "$TAG" \
               --arg now "$NOW" \
               --argjson size "${SIZE_MB:-0}" \
               '.repositories[$url] = {
                 "owner": $owner,
                 "repo": $repo,
                 "description": $desc,
                 "status": $status,
                 "first_archived": $now,
                 "last_archived": $now,
                 "archive_count": 1,
                 "latest_release_tag": $tag,
                 "latest_size_mb": $size
               } | .total_repos += 1 | .total_size_mb += $size | .last_updated = $now' \
               index.json > index_new.json
          else
            # Update existing repository
            PREV_COUNT=$(jq -r ".repositories[\"$REPO_URL\"].archive_count // 0" index.json)
            NEW_COUNT=$((PREV_COUNT + 1))

            jq --arg url "$REPO_URL" \
               --arg tag "$TAG" \
               --arg now "$NOW" \
               --argjson size "${SIZE_MB:-0}" \
               --argjson count "$NEW_COUNT" \
               '.repositories[$url].last_archived = $now |
                .repositories[$url].latest_release_tag = $tag |
                .repositories[$url].latest_size_mb = $size |
                .repositories[$url].archive_count = $count |
                .last_updated = $now' \
               index.json > index_new.json
          fi

          mv index_new.json index.json

          # Recalculate total_size_mb from all repositories
          TOTAL_SIZE=$(jq '[.repositories[].latest_size_mb] | add // 0' index.json)
          jq --argjson total "$TOTAL_SIZE" '.total_size_mb = $total' index.json > index_final.json
          mv index_final.json index.json

          cat index.json

          # Schema validation function
          validate_index() {
            local file=$1

            # Check required top-level fields
            if ! jq -e '.repositories and .total_repos != null and .total_size_mb != null and .last_updated' "$file" > /dev/null 2>&1; then
              echo "ERROR: Missing required top-level fields"
              return 1
            fi

            # Check total_repos is a number
            if ! jq -e '.total_repos | type == "number"' "$file" > /dev/null 2>&1; then
              echo "ERROR: total_repos must be a number"
              return 1
            fi

            # Check repositories is an object
            if ! jq -e '.repositories | type == "object"' "$file" > /dev/null 2>&1; then
              echo "ERROR: repositories must be an object"
              return 1
            fi

            # Verify count matches
            ACTUAL_COUNT=$(jq '.repositories | length' "$file")
            STATED_COUNT=$(jq '.total_repos' "$file")

            if [ "$ACTUAL_COUNT" != "$STATED_COUNT" ]; then
              echo "WARNING: Fixing total_repos mismatch ($STATED_COUNT -> $ACTUAL_COUNT)"
              jq --argjson count "$ACTUAL_COUNT" '.total_repos = $count' "$file" > "${file}.tmp"
              mv "${file}.tmp" "$file"
            fi

            echo "Index validation passed"
            return 0
          }

          # Validate before uploading
          if ! validate_index index.json; then
            echo "Index validation failed - aborting"
            exit 1
          fi

      - name: Upload index
        if: steps.validate.outputs.valid == 'true' && steps.check_changes.outputs.has_changes == 'true'
        uses: softprops/action-gh-release@v1
        with:
          tag_name: index
          name: "Repository Index"
          body: "Master index of all archived repositories. Auto-updated."
          files: index.json
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Comment on issue (success - new archive)
        if: github.event_name == 'issues' && steps.validate.outputs.valid == 'true' && steps.check_changes.outputs.has_changes == 'true'
        uses: actions/github-script@v7
        with:
          script: |
            const tag = '${{ steps.parse.outputs.tag }}';
            const owner = '${{ steps.parse.outputs.owner }}';
            const repo = '${{ steps.parse.outputs.repo }}';
            const sizeMB = '${{ steps.archive.outputs.archive_size_mb }}';
            const archiveName = '${{ steps.archive.outputs.archive_name }}';

            const downloadUrl = `https://github.com/${context.repo.owner}/${context.repo.repo}/releases/download/${tag}/${archiveName}`;

            await github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `✅ **Archive created successfully!**

            **Repository:** ${owner}/${repo}
            **Size:** ${sizeMB}MB
            **Download:** [${archiveName}](${downloadUrl})

            This issue will now be closed.`
            });

            await github.rest.issues.update({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              state: 'closed',
              labels: ['archive-request', 'completed']
            });

      - name: Comment on issue (no changes)
        if: github.event_name == 'issues' && steps.validate.outputs.valid == 'true' && steps.check_changes.outputs.has_changes == 'false'
        uses: actions/github-script@v7
        with:
          script: |
            const owner = '${{ steps.parse.outputs.owner }}';
            const repo = '${{ steps.parse.outputs.repo }}';

            await github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `ℹ️ **No changes detected**

            The repository **${owner}/${repo}** has not changed since the last archive.

            No new release was created. You can download the existing archive from the releases page.

            This issue will now be closed.`
            });

            await github.rest.issues.update({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              state: 'closed',
              labels: ['archive-request', 'no-changes']
            });

      - name: Comment on issue (failure)
        if: github.event_name == 'issues' && (steps.parse.outputs.valid != 'true' || steps.validate.outputs.valid != 'true')
        uses: actions/github-script@v7
        with:
          script: |
            const parseValid = '${{ steps.parse.outputs.valid }}';
            const validateValid = '${{ steps.validate.outputs.valid }}';
            const error = '${{ steps.validate.outputs.error }}' || 'Invalid repository URL';

            let message = '❌ **Archive failed**\n\n';

            if (parseValid !== 'true') {
              message += 'Could not parse repository URL from issue body.\n\n';
              message += 'Please ensure the issue contains a line like:\n';
              message += '```\nurl: https://github.com/owner/repo\n```';
            } else {
              message += `**Reason:** ${error}`;
            }

            await github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: message
            });

            await github.rest.issues.update({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              state: 'closed',
              labels: ['archive-request', 'failed']
            });

      - name: Cleanup old backups
        if: always()
        run: |
          echo "Cleaning up old index backups (keeping last 10)..."

          # List all backup releases, sorted by creation date (newest first)
          BACKUP_RELEASES=$(gh release list --limit 100 --json tagName,createdAt \
            --jq '[.[] | select(.tagName | startswith("index-backup-"))] | sort_by(.createdAt) | reverse | .[].tagName')

          if [ -z "$BACKUP_RELEASES" ]; then
            echo "No backup releases found"
            exit 0
          fi

          # Count total backups
          TOTAL_BACKUPS=$(echo "$BACKUP_RELEASES" | wc -l | tr -d ' ')
          echo "Found $TOTAL_BACKUPS backup releases"

          # Keep only last 10, delete the rest
          KEEP_COUNT=10
          if [ "$TOTAL_BACKUPS" -le "$KEEP_COUNT" ]; then
            echo "Only $TOTAL_BACKUPS backups exist, nothing to delete"
            exit 0
          fi

          # Get backups to delete (skip first 10)
          BACKUPS_TO_DELETE=$(echo "$BACKUP_RELEASES" | tail -n +$((KEEP_COUNT + 1)))
          DELETE_COUNT=$(echo "$BACKUPS_TO_DELETE" | wc -l | tr -d ' ')

          echo "Will delete $DELETE_COUNT old backups"

          # Delete old backups
          while IFS= read -r tag; do
            if [ -n "$tag" ]; then
              echo "Deleting backup: $tag"
              gh release delete "$tag" --yes --cleanup-tag || echo "Warning: Failed to delete $tag"
            fi
          done <<< "$BACKUPS_TO_DELETE"

          echo "Cleanup complete"
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Cleanup on failure
        if: failure() || cancelled()
        run: |
          rm -rf repo *.tar.gz index*.json
